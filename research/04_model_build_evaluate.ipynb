{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sleep Disorder Model Build and evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Projects\\\\Sleeping_disorder_detection\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Projects\\\\Sleeping_disorder_detection'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelBuildEvaluateConfig:\n",
    "    root_dir: Path\n",
    "    model_dir: Path\n",
    "    model_file: Path\n",
    "    train_data_file: Path\n",
    "    test_data_file: Path\n",
    "    model_results_file: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sleep_disorder.constants import *\n",
    "from sleep_disorder.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_file_path=CONFIG_FILE_PATH, params_file_path=PARAMS_FILE_PATH) -> None:\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "    def get_model_build_evaluate_config(self) -> ModelBuildEvaluateConfig:\n",
    "        config = self.config.model_build_evaluate\n",
    "\n",
    "        model_build_evaluate_config = ModelBuildEvaluateConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            model_dir=config.model_dir,\n",
    "            model_file=config.model_file,\n",
    "            train_data_file=config.train_data_file,\n",
    "            test_data_file=config.test_data_file,\n",
    "            model_results_file=config.model_results_file,\n",
    "        )\n",
    "\n",
    "        return model_build_evaluate_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sleep_disorder.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(name, accuracy, recall, precision, f1):\n",
    "    results = pd.DataFrame()\n",
    "    results['Name'] = name\n",
    "    results['Accuracy'] = accuracy\n",
    "    results['Recall'] = recall\n",
    "    results['Precision'] = precision\n",
    "    results['F1_score'] = f1\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuildEvaluate:\n",
    "    def __init__(self, config: ModelBuildEvaluateConfig) -> None:\n",
    "        self.config = config\n",
    "\n",
    "        create_directories([self.config.root_dir, self.config.model_dir])\n",
    "\n",
    "    def train_model(self):\n",
    "        models = {\n",
    "            \"LogisticRegression\": LogisticRegression(),\n",
    "            \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "            \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "            \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "            \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "            \"SVC\": SVC(),\n",
    "            \"XGBClassifier\": XGBClassifier(),\n",
    "            \"CatBoostClassifier\": CatBoostClassifier(verbose=False),\n",
    "        }\n",
    "\n",
    "        train_data = pd.read_csv(self.config.train_data_file)\n",
    "\n",
    "        X_train = train_data.drop(columns=\"Sleep Disorder\")\n",
    "        y_train = train_data[\"Sleep Disorder\"]\n",
    "\n",
    "        trained_models = {}\n",
    "\n",
    "        name = []\n",
    "        accuracy = []\n",
    "        recall = []\n",
    "        precision = []\n",
    "        f1 = []\n",
    "\n",
    "        for model_name in models.keys():\n",
    "            model = models[model_name]\n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_train)\n",
    "            print(f\"Train data {model_name} Classification Report:\\n{classification_report(y_train, pred)}\\n\\n\\n\")\n",
    "            name.append(model_name)\n",
    "            accuracy.append(accuracy_score(y_train, pred))\n",
    "            recall.append(recall_score(y_train, pred, average=\"macro\"))\n",
    "            precision.append(precision_score(y_train, pred, average=\"macro\"))\n",
    "            f1.append(f1_score(y_train, pred, average=\"macro\"))\n",
    "            trained_models[model_name] = model\n",
    "\n",
    "        results = get_results(name, accuracy, recall, precision, f1)\n",
    "\n",
    "        return trained_models, results\n",
    "\n",
    "    def test_model(self, train_models):\n",
    "        test_data = pd.read_csv(self.config.test_data_file)\n",
    "\n",
    "        X_test = test_data.drop(columns=\"Sleep Disorder\")\n",
    "        y_test = test_data[\"Sleep Disorder\"]\n",
    "\n",
    "        name = []\n",
    "        accuracy = []\n",
    "        recall = []\n",
    "        precision = []\n",
    "        f1 = []\n",
    "\n",
    "        print(\"\\n\\n\\n\\n\\nTest Results:\")\n",
    "\n",
    "        for model_name in train_models.keys():\n",
    "            model = train_models[model_name]\n",
    "            model.fit(X_test, y_test)\n",
    "            pred = model.predict(X_test)\n",
    "            print(f\"Test data {model_name} Classification Report:\\n{classification_report(y_test, pred)}\\n\\n\\n\")\n",
    "            name.append(model_name)\n",
    "            accuracy.append(accuracy_score(y_test, pred))\n",
    "            recall.append(recall_score(y_test, pred, average=\"macro\"))\n",
    "            precision.append(precision_score(y_test, pred, average=\"macro\"))\n",
    "            f1.append(f1_score(y_test, pred, average=\"macro\"))\n",
    "\n",
    "        results = get_results(name, accuracy, recall, precision, f1)\n",
    "\n",
    "        best_model_name = list(results.sort_values('Accuracy', ascending=False)[\"Name\"])[0]\n",
    "\n",
    "        best_model = train_models[best_model_name]\n",
    "\n",
    "        return best_model, results\n",
    "\n",
    "    def save_model(self, model):\n",
    "        with open(self.config.model_file, \"wb\") as model_pkl:\n",
    "            pickle.dump(model, model_pkl)\n",
    "            logger.info(f\"Best model saved to path: {self.config.model_file}\")\n",
    "\n",
    "    def save_test_results(self, test_results):\n",
    "        with open(self.config.model_results_file, \"w\") as f:\n",
    "            f.write(test_results)\n",
    "            logger.info(f\"All model results saved to path: {self.config.model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-22 01:15:47,746]: INFO common yaml file: config\\config.yaml loaded successfully.\n",
      "[2023-12-22 01:15:47,749]: INFO common yaml file: params.yaml loaded successfully.\n",
      "[2023-12-22 01:15:47,751]: INFO common Directory created at: artifacts/model_evaluation\n",
      "[2023-12-22 01:15:47,752]: INFO common Directory created at: model\n",
      "Train data LogisticRegression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       157\n",
      "           1       0.90      0.83      0.86        52\n",
      "           2       0.85      0.42      0.56        52\n",
      "\n",
      "    accuracy                           0.82       261\n",
      "   macro avg       0.85      0.74      0.77       261\n",
      "weighted avg       0.83      0.82      0.81       261\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train data DecisionTreeClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       157\n",
      "           1       0.89      0.98      0.94        52\n",
      "           2       0.96      0.85      0.90        52\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.93      0.93       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train data RandomForestClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       157\n",
      "           1       0.92      0.94      0.93        52\n",
      "           2       0.92      0.88      0.90        52\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.93      0.93       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train data GradientBoostingClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       157\n",
      "           1       0.92      0.94      0.93        52\n",
      "           2       0.92      0.88      0.90        52\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.93      0.93       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train data AdaBoostClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       157\n",
      "           1       0.86      0.35      0.49        52\n",
      "           2       0.56      0.81      0.66        52\n",
      "\n",
      "    accuracy                           0.71       261\n",
      "   macro avg       0.72      0.65      0.64       261\n",
      "weighted avg       0.74      0.71      0.70       261\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train data SVC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78       157\n",
      "           1       0.81      0.40      0.54        52\n",
      "           2       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.66       261\n",
      "   macro avg       0.48      0.46      0.44       261\n",
      "weighted avg       0.55      0.66      0.57       261\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train data XGBClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       157\n",
      "           1       0.92      0.94      0.93        52\n",
      "           2       0.92      0.88      0.90        52\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.93      0.93       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train data CatBoostClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       157\n",
      "           1       0.89      0.98      0.94        52\n",
      "           2       0.96      0.85      0.90        52\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.93      0.93       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Test Results:\n",
      "Test data LogisticRegression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.89      0.81        62\n",
      "           1       0.83      0.38      0.53        26\n",
      "           2       0.74      0.80      0.77        25\n",
      "\n",
      "    accuracy                           0.75       113\n",
      "   macro avg       0.77      0.69      0.70       113\n",
      "weighted avg       0.76      0.75      0.74       113\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Test data DecisionTreeClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94        62\n",
      "           1       0.88      0.85      0.86        26\n",
      "           2       0.92      0.92      0.92        25\n",
      "\n",
      "    accuracy                           0.92       113\n",
      "   macro avg       0.91      0.91      0.91       113\n",
      "weighted avg       0.92      0.92      0.92       113\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Test data RandomForestClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94        62\n",
      "           1       0.88      0.85      0.86        26\n",
      "           2       0.92      0.92      0.92        25\n",
      "\n",
      "    accuracy                           0.92       113\n",
      "   macro avg       0.91      0.91      0.91       113\n",
      "weighted avg       0.92      0.92      0.92       113\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Test data GradientBoostingClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94        62\n",
      "           1       0.88      0.85      0.86        26\n",
      "           2       0.92      0.92      0.92        25\n",
      "\n",
      "    accuracy                           0.92       113\n",
      "   macro avg       0.91      0.91      0.91       113\n",
      "weighted avg       0.92      0.92      0.92       113\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Test data AdaBoostClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87        62\n",
      "           1       0.72      0.69      0.71        26\n",
      "           2       0.92      0.88      0.90        25\n",
      "\n",
      "    accuracy                           0.84       113\n",
      "   macro avg       0.83      0.82      0.83       113\n",
      "weighted avg       0.84      0.84      0.84       113\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Test data SVC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71        62\n",
      "           1       0.00      0.00      0.00        26\n",
      "           2       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.55       113\n",
      "   macro avg       0.18      0.33      0.24       113\n",
      "weighted avg       0.30      0.55      0.39       113\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Test data XGBClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94        62\n",
      "           1       0.88      0.85      0.86        26\n",
      "           2       0.92      0.92      0.92        25\n",
      "\n",
      "    accuracy                           0.92       113\n",
      "   macro avg       0.91      0.91      0.91       113\n",
      "weighted avg       0.92      0.92      0.92       113\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Test data CatBoostClassifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94        62\n",
      "           1       0.88      0.85      0.86        26\n",
      "           2       0.92      0.92      0.92        25\n",
      "\n",
      "    accuracy                           0.92       113\n",
      "   macro avg       0.91      0.91      0.91       113\n",
      "weighted avg       0.92      0.92      0.92       113\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[2023-12-22 01:15:51,428]: INFO 2832317789 Best model saved to path: model/model.pkl\n",
      "[2023-12-22 01:15:51,432]: INFO 2832317789 All model results saved to path: model/model.pkl\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_train_evaluate_config = config.get_model_build_evaluate_config()\n",
    "    model_build_evaluate = ModelBuildEvaluate(config=model_train_evaluate_config)\n",
    "    train_models, train_results = model_build_evaluate.train_model()\n",
    "    best_model, test_results = model_build_evaluate.test_model(train_models=train_models)\n",
    "    model_build_evaluate.save_model(best_model)\n",
    "    model_build_evaluate.save_test_results(test_results=str(test_results))\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
